{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Scott Wilkinson (V00887986) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: KNN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook which uses a KNN regression model to predict the time of merger of simulated galaxies from IllustrisTNG based on their non-parametric morphology data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must import the necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages used in notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.io.fits as pyfits\n",
    "import pymysql, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTW if you need a package installed, you can use the following\n",
    "\n",
    "#import os\n",
    "#os.system('pip install pymysql')\n",
    "#os.system('pip install corner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My field of study is of galaxy morphology and evolution. Specifically, I tend to focus on the observability and detection of galaxy mergers or post-mergers. Wilkinson et al. (in prep.) approaches this from the perspective of post-starburst galaxies. In my next project, I hope to determine how many mergers are missed by the methods used within Wilkinson et al. (in prep.). To test how many mergers are detected, it is best to start with a sample of galaxies that you KNOW are mergers. Cosmological simulations provide just that: a sample of galaxies that have recently merged, with all details (mass, time since merger, etc.) known as truth rather than a measurement/estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, I wish to answer a series of related but slightly different questions:\n",
    "\n",
    "1. Can a neural network use statistical morphology metrics to reliably identify post-merger galaxies and pre-merger galaxies (tabular - classification)?\n",
    "\n",
    "2. Can a neural network use statistical morphology metrics to predict when a galaxy merger will (or did) coalesce (tabular - regression)?\n",
    "\n",
    "3. Can a neural network use a galaxy's semi-realistic image to reliably identify post-merger galaxies and pre-merger galaxies (image - classification)?\n",
    "\n",
    "4. Can a neural network use a galaxy's semi-realistic image to predict when a galaxy merger will (or did) coalesce (image - regression)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer these questions, I need tabular morphology data and realistic imaging for post-merger and pre-merger galaxies. I have already generated semi-realistic images for all galaxies in the IllustrisTNG cosmological simulation (~300,000) at varying levels of image quality (PSF blurring and sky noise). Moreover, I have a morphology catalogue for CFIS-realistic images generated using RealSimCFIS pipeline (Bottrell et al. 2019) and used in Bickley et al. (2021). I will start with these images and their derived non-parametric morphology statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Morphology Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I require the galaxy morphology that I computed to have not been flagged (flag_morph = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asymmetry < -1 is caused by too much sky noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 219933)\n"
     ]
    }
   ],
   "source": [
    "#Query SQL for morphology data\n",
    "# connects to database\n",
    "db = pymysql.connect(host = 'lauca.phys.uvic.ca', db = 'sdss', user = 'swilkinson', passwd = '123Sdss!@#')\n",
    "# select morphology params that have unflagged morphology fits\n",
    "x = 'SELECT  dbID, asymmetry, shape_asymmetry, gini_m20_merger, concentration, outer_asymmetry, deviation, multimode, intensity \\\n",
    "    FROM simCFIS_morph\\\n",
    "    WHERE flag_morph = 0\\\n",
    "    AND asymmetry > -1'\n",
    "c = db.cursor()\n",
    "c.execute(x)\n",
    "db_data = c.fetchall()\n",
    "c.close()\n",
    "db.close()\n",
    "\n",
    "# save names as a string\n",
    "names_morph = np.array(db_data, dtype = str).T[0]\n",
    "\n",
    "# save rest of data as floats\n",
    "morph = np.array(db_data, dtype = float).T[1:]\n",
    "\n",
    "print(morph.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merger Sample Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Sample of Pre-Merger Galaxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the reasoning behind my selection cuts:\n",
    "\n",
    "1.  snap >= 50 requires z<1 in the simulation (ie. enough time for galaxies to form, evolve and begin to merge)\n",
    "2. rsep > 0 requires there to be two merging galaxies that are not on top of each other yet\n",
    "3. mass ratio > 0.1, the merger will be significant when it occurs\n",
    "4. Flaguntilmerger = 1 ensures the merger is true and not a projection effect that confuses the `subfind` code (see Hani et al. 2020, Rodriguez-Gomez et al. 2015)\n",
    "5. Tuntilmerger < 0.5 ensures the merger will happen soon (< 500 Myr) and the galaxies have begun to gravitationally interact\n",
    "6. Tpostmerger > 0.5 ensures no recent has occurred that would cause the disturbed morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7322 pre-merger galaxies.\n",
      "There are 2886 pre-merger galaxies with flag-free morphology data.\n"
     ]
    }
   ],
   "source": [
    "#Query MySQL with reasoning described above\n",
    "db = pymysql.connect(host = 'lauca.phys.uvic.ca', db = 'IllustrisTNG100_1', user = 'swilkinson', passwd = '123Sdss!@#')\n",
    "x ='SELECT e.DB_ID, e.Mstar, e.Tuntilmerger, e.MassRatiountilmerger\\\n",
    "    FROM Environment e \\\n",
    "    WHERE snapNum>=50\\\n",
    "    AND rsep>0 \\\n",
    "    AND MassRatiountilmerger>=0.1\\\n",
    "    AND Flaguntilmerger = 1\\\n",
    "    AND Tuntilmerger < 0.5\\\n",
    "    AND Tpostmerger > 0.5'\n",
    "c = db.cursor()\n",
    "c.execute(x)\n",
    "db_data = c.fetchall()\n",
    "c.close()\n",
    "db.close()\n",
    "\n",
    "names_db_pre = np.array(db_data, dtype = str).T[0]\n",
    "Mstar_pre = np.array(db_data, dtype = float).T[1]\n",
    "Tum_pre = np.array(db_data, dtype = float).T[2]\n",
    "mu_pre = np.array(db_data, dtype = float).T[3]\n",
    "\n",
    "# give time before merger a negative value\n",
    "Tum_pre *= -1\n",
    "\n",
    "# differentiate pre-merger galaxies that merge within the next snapshot from post-merger galaxies\n",
    "#   that have merged within the last snap shot by adding / subtracting 0.1Gyr (approx the middle of a snapshot)\n",
    "Tum_pre[Tum_pre == 0] = -0.05\n",
    "\n",
    "# add 0 to match formatting with morphology catalogue\n",
    "names_db_pre = np.array(['0'+n for n in names_db_pre])\n",
    "\n",
    "print('There are {} pre-merger galaxies.'.format(len(names_db_pre)))\n",
    "\n",
    "# match the two catalogues\n",
    "match, idx_morph_pre, idx_pre = np.intersect1d(names_morph, names_db_pre, return_indices = True)\n",
    "\n",
    "print('There are {} pre-merger galaxies with flag-free morphology data.'.format(len(names_db_pre[idx_pre])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a Sample of Post-Merger Galaxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the reasoning behind my selection cuts:\n",
    "\n",
    "1. snap >= 50 requires z<1 in the simulation (ie. enough time for galaxies to form, evolve and begin to merge)\n",
    "2. mass ratio > 0.1, the merger that occurred was significant\n",
    "3. Flagpostmerger = 1 ensures the merger is true and not a projection effect that confuses the `subfind` code\n",
    "4. Tpostmerger < 0.5 requires a merger to have occurred in the last 500 Myr\n",
    "5. rsep > 25 and Tuntilmerger < 0.5 requires there to be no nearby galaxies about to cause another merger in the next 500 Myr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5153 post-merger galaxies.\n",
      "There are 3456 post-merger galaxies with flag-free morphology data.\n"
     ]
    }
   ],
   "source": [
    "#Query MySQL with the reasoning listed above\n",
    "db = pymysql.connect(host = 'lauca.phys.uvic.ca', db = 'IllustrisTNG100_1', user = 'swilkinson', passwd = '123Sdss!@#')\n",
    "x ='SELECT e.DB_ID, e.Mstar, e.Tpostmerger, e.MassRatio\\\n",
    "    FROM Environment e \\\n",
    "    WHERE snapNum>=50\\\n",
    "    AND MassRatio>=0.1\\\n",
    "    AND Flagpostmerger = 1\\\n",
    "    AND Tpostmerger < 0.5\\\n",
    "    AND rsep>25\\\n",
    "    AND Tuntilmerger > 0.5'\n",
    "c = db.cursor()\n",
    "c.execute(x)\n",
    "db_data = c.fetchall()\n",
    "c.close()\n",
    "db.close()\n",
    "\n",
    "names_db_post = np.array(db_data, dtype = str).T[0]\n",
    "Mstar_post = np.array(db_data, dtype = float).T[1]\n",
    "Tpm_post = np.array(db_data, dtype = float).T[2]\n",
    "mu_post = np.array(db_data, dtype = float).T[3]\n",
    "\n",
    "# add 0 to match formatting with morphology catalogue\n",
    "names_db_post = np.array(['0'+n for n in names_db_post])\n",
    "\n",
    "# differentiate pre-merger galaxies that merge within the next snapshot from post-merger galaxies\n",
    "#   that have merged within the last snap shot by adding / subtracting 0.1Gyr (approx the middle of a snapshot)\n",
    "Tpm_post[Tpm_post == 0] = 0.05\n",
    "\n",
    "print('There are {} post-merger galaxies.'.format(len(names_db_post)))\n",
    "\n",
    "# match with morphology catalogue\n",
    "match, idx_morph_post, idx_post = np.intersect1d(names_morph, names_db_post, return_indices = True)\n",
    "\n",
    "print('There are {} post-merger galaxies with flag-free morphology data.'.format(len(names_db_post[idx_post])))\n",
    "\n",
    "names_db_post = names_db_post[idx_post]\n",
    "Mstar_post = Mstar_post[idx_post]\n",
    "Tpm_post = Tpm_post[idx_post]\n",
    "mu_post = mu_post[idx_post]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all merging galaxies\n",
    "names_mergers = np.array(list(names_db_pre) + list(names_db_post))\n",
    "T_merger = np.array(list(Tum_pre) + list(Tpm_post))\n",
    "mu = np.array(list(mu_pre) + list(mu_post))\n",
    "mass = np.array(list(Mstar_pre) + list(Mstar_post))\n",
    "\n",
    "# match catalogues\n",
    "match, idx_morph, idx_merge = np.intersect1d(names_morph, names_mergers, return_indices = True)\n",
    "\n",
    "T_merger = T_merger[idx_merge]\n",
    "mu = mu[idx_merge]\n",
    "mass = mass[idx_merge]\n",
    "morph = morph[:,idx_morph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6342)\n"
     ]
    }
   ],
   "source": [
    "# shape of output\n",
    "print(morph.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6342,)\n"
     ]
    }
   ],
   "source": [
    "# shape of output\n",
    "print(T_merger.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation sets (75/25 split)\n",
    "input_tr,input_va,target_tr, target_va = train_test_split(morph.T, T_merger,test_size=0.25, shuffle = True)\n",
    "#input_tr,input_va,target_tr, target_va = train_test_split(morph.T, mu, test_size=0.25, shuffle = True)\n",
    "#input_tr,input_va,target_tr, target_va = train_test_split(morph.T, mass,test_size=0.25, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalizing inputs\n",
    "\n",
    "# fit on training set\n",
    "scaler = StandardScaler().fit(input_tr)  \n",
    "\n",
    "# normalize training\n",
    "input_tr_norm= scaler.transform(input_tr) \n",
    "\n",
    "# normalize validation with same scaler & fit\n",
    "input_va_norm= scaler.transform(input_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper parameters\n",
    "SGD = linear_model.SGDRegressor(loss='squared_loss', penalty='L2', alpha=0.01, l1_ratio=0.015, \n",
    "                                        fit_intercept=True, max_iter=100, tol=0.0011, shuffle=True, verbose=0, \n",
    "                                        epsilon=0.01, random_state=None, learning_rate='constant', eta0=0.01, \n",
    "                                        power_t=0.25, early_stopping=True, validation_fraction=0.25, \n",
    "                                        n_iter_no_change=5, warm_start=False, average=False)\n",
    "# fit the model with training set\n",
    "SGD.fit(input_tr_norm,target_tr)  \n",
    "\n",
    "#'predictions for training and validation sets'\n",
    "target_tr_pred= SGD.predict(input_tr_norm)  \n",
    "target_va_pred= SGD.predict(input_va_norm)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(target_tr,target_tr_pred,'ob')\n",
    "plt.plot(target_va,target_va_pred,'.r')\n",
    "plt.plot(target_tr, target_tr, '--')\n",
    "plt.xlabel('True T')\n",
    "plt.ylabel('Predicted T')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(target_tr,target_tr_pred-target_tr,'o', color = 'tab:blue')\n",
    "plt.plot(target_va,target_va_pred-target_va,'.', color = 'tab:red')\n",
    "plt.plot(target_tr,np.zeros(len(target_tr)), '-k')\n",
    "plt.xlabel('True T')\n",
    "plt.ylabel('Predicted T')\n",
    "plt.show()\n",
    "\n",
    "plt.legend(['Training', 'Validation'])\n",
    "#plt.xlim([-100000,600000])\n",
    "#plt.ylim([-100000,600000])\n",
    "#plt.plot([-100000,600000],[-100000,600000],'--k')\n",
    "#Statistical information regarding training and validation predictions\n",
    "#mu = np.mean(Y_tr-Y_tr_pred)\n",
    "#median = np.median(Y_tr-Y_tr_pred)\n",
    "#sigma = np.std(Y_tr-Y_tr_pred)\n",
    "\n",
    "#muv = np.mean(Y_va-Y_va_pred)\n",
    "#medianv = np.median(Y_va-Y_va_pred)\n",
    "#sigmav = np.std(Y_va-Y_va_pred)\n",
    "\n",
    "#textstr = '$\\mu=%.4f$\\n$\\mathrm{med}=%.4f$\\n$\\sigma=%.4f$'%(mu, median, sigma)\n",
    "#textstrv = '$\\mu=%.4f$\\n$\\mathrm{med}=%.4f$\\n$\\sigma=%.4f$'%(muv, medianv, sigmav)\n",
    "\n",
    "\n",
    "#plt.text(700000,100,textstr, color='b',fontsize=18)\n",
    "#plt.text(700000,300000,textstrv, color='r',fontsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(target_tr_pred, bins = 50)\n",
    "plt.hist(target_tr, bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried tweaking hyper parameters... no luck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying feature extraction.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "\n",
    "poly = PolynomialFeatures(degree,include_bias=False)\n",
    "poly.fit(input_tr_norm)\n",
    "\n",
    "input_tr_norm_ext = poly.transform(input_tr_norm)\n",
    "input_va_norm_ext = poly.transform(input_va_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper parameters\n",
    "SGD = linear_model.SGDRegressor(loss='squared_loss', penalty='L2', alpha=0.1, l1_ratio=0.15, \n",
    "                                        fit_intercept=True, max_iter=100, tol=0.00001, shuffle=True, verbose=0, \n",
    "                                        epsilon=0.1, random_state=None, learning_rate='constant', eta0=0.01, \n",
    "                                        power_t=0.25, early_stopping=True, validation_fraction=0.1, \n",
    "                                        n_iter_no_change=5, warm_start=False, average=False)\n",
    "# fit the model with training set\n",
    "SGD.fit(input_tr_norm_ext,target_tr)  \n",
    "\n",
    "#'predictions for training and validation sets'\n",
    "target_tr_pred= SGD.predict(input_tr_norm_ext)  \n",
    "target_va_pred= SGD.predict(input_va_norm_ext)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(target_tr,target_tr_pred,'ob')\n",
    "plt.plot(target_va,target_va_pred,'.r')\n",
    "plt.plot(target_tr, target_tr, '--')\n",
    "plt.xlabel('True T')\n",
    "plt.ylabel('Predicted T')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(target_tr,target_tr_pred-target_tr,'o', color = 'tab:blue')\n",
    "plt.plot(target_va,target_va_pred-target_va,'.', color = 'tab:red')\n",
    "plt.plot(target_tr,np.zeros(len(target_tr)), '-k')\n",
    "plt.xlabel('True T')\n",
    "plt.ylabel('Predicted T - True T')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "plt.hist(target_tr_pred, bins = 100, range = [-2,2])\n",
    "plt.hist(target_tr, bins = 100, range = [-2,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(target_tr_pred), bins = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(input_tr.T[0],target_tr, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper parameters\n",
    "KNN = KNeighborsRegressor(n_neighbors=3, p=2)\n",
    "\n",
    "# fit the model with training set\n",
    "KNN.fit(input_tr_norm,target_tr)  \n",
    "\n",
    "#'predictions for training and validation sets'\n",
    "target_tr_pred= KNN.predict(input_tr_norm)  \n",
    "target_va_pred= KNN.predict(input_va_norm)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(target_tr,target_tr_pred,'ob')\n",
    "plt.plot(target_va,target_va_pred,'.r')\n",
    "plt.plot(target_tr, target_tr, '--')\n",
    "plt.xlabel('True T')\n",
    "plt.ylabel('Predicted T')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(target_tr,target_tr_pred-target_tr,'o', color = 'tab:blue')\n",
    "plt.plot(target_va,target_va_pred-target_va,'.', color = 'tab:red')\n",
    "plt.plot(target_tr,np.zeros(len(target_tr)), '-k')\n",
    "plt.xlabel('True T')\n",
    "plt.ylabel('Predicted T')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "plt.hist(target_tr_pred, bins = 100, range = [10,12], alpha = 0.5)\n",
    "plt.hist(target_tr, bins = 100, range = [10,12], alpha = 0.5)\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "plt.hist(target_va_pred, bins = 100, range = [10,12], alpha = 0.5)\n",
    "plt.hist(target_va, bins = 100, range = [10,12], alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
